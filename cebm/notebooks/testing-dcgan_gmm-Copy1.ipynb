{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from sebm.models import Generator_GMM, Discriminator\n",
    "dataset =  'svhn' # 'svhn' # 'cifar10' # 'mnist' #  'flowers102' #\n",
    "if dataset == 'mnist' or dataset =='fashionmnist':\n",
    "    input_channels, im_height, im_width = 1, 28, 28\n",
    "else:\n",
    "    input_channels, im_height, im_width = 3, 32, 32\n",
    "device = torch.device('cuda:0')\n",
    "arch =  'simplenet'\n",
    "seed = 1\n",
    "lr = 2e-4\n",
    "GMM_components = 50\n",
    "if dataset == 'cifar10' or dataset == 'svhn':\n",
    "    disc_channels, disc_kernels, disc_strides, disc_paddings = [64,128,256,512], [3,4,4,4], [1,2,2,2], [1,1,1,1]\n",
    "    gen_channels, gen_kernels, gen_strides, gen_paddings = [512,256,128,64,3], [4,4,4,4,4], [2,2,2,2,2], [1,1,1,1,1]\n",
    "    hidden_dim = [128,128]\n",
    "    latent_dim, disc_activation, gen_activation = 128, 'LeakyReLU', 'ReLU'\n",
    "    leak = 0.2\n",
    "elif dataset == 'mnist' or dataset == 'fashionmnist':\n",
    "    disc_channels, disc_kernels, disc_strides, disc_paddings = [64,64,32,32], [3,4,4,4], [1,2,2,2], [1,1,1,1]\n",
    "    gen_channels, gen_kernels, gen_strides, gen_paddings = [64,64,32,32,1], [4,4,3,4,4], [1,2,2,2,2], [1,1,1,1,1] \n",
    "    hidden_dim = [128,128]\n",
    "\n",
    "    latent_dim, disc_activation, gen_activation = 128, 'LeakyReLU', 'ReLU'\n",
    "    leak = 0.2\n",
    "else:\n",
    "    raise NotImplementError\n",
    "data_dir = '../../../sebm_data/'\n",
    "load_version = 'dcgan_gmm-d=%s-seed=%d-lr=%s-zd=%d-disc_act=%s-gen_act=%s-arch=%s' % (dataset, seed, lr, latent_dim, disc_activation, gen_activation, arch)\n",
    "arch= 'simplenet'\n",
    "gen = Generator_GMM(arch=arch,\n",
    "                    learn_prior=True,\n",
    "                    K=GMM_components,\n",
    "                    device=device,\n",
    "                    im_height=1, \n",
    "                    im_width=1, \n",
    "                    input_channels=latent_dim, \n",
    "                    channels=gen_channels, \n",
    "                    kernels=gen_kernels, \n",
    "                    strides=gen_strides, \n",
    "                    paddings=gen_paddings, \n",
    "                    activation=gen_activation,\n",
    "                    leak=leak,\n",
    "                    batchnorm=True)\n",
    "\n",
    "disc = Discriminator(arch=arch,\n",
    "                    im_height=im_height, \n",
    "                    im_width=im_width, \n",
    "                    input_channels=input_channels, \n",
    "                    channels=disc_channels, \n",
    "                    kernels=disc_kernels, \n",
    "                    strides=disc_strides, \n",
    "                    paddings=disc_paddings, \n",
    "                    hidden_dim=hidden_dim,\n",
    "                    latent_dim=1,\n",
    "                    activation=disc_activation,\n",
    "                    leak=leak,\n",
    "                    batchnorm=True)    \n",
    "\n",
    "gen = gen.cuda().to(device)\n",
    "disc = disc.cuda().to(device)\n",
    "print('Loading trained weights..')\n",
    "gen.load_state_dict(torch.load('../weights/cp-%s' % load_version)['gen_state_dict'])\n",
    "disc.load_state_dict(torch.load('../weights/cp-%s' % load_version)['disc_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sebm.eval import Evaluator_GAN, fewshots\n",
    "evaluator = Evaluator_GAN((disc, gen), device, dataset, data_dir)\n",
    "evaluator.plot_samples(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fewshots(model_name='dcgan_gmm', evaluator=evaluator, list_num_shots=[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity_z_space(evaluator, \n",
    "#                        train_batch_size=2000, \n",
    "#                        test_batch_size=2000,\n",
    "#                        model_name='igebm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = evaluator.oodauc(dataset_ood='texture', score='gradient')\n",
    "# scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images_ebm = evaluator.uncond_sampling(batch_size=100, \n",
    "#                                           sgld_steps=1000,\n",
    "#                                           sgld_lr=2.0,\n",
    "#                                           sgld_noise_std=1e-3,\n",
    "#                                           grad_clipping=False,\n",
    "#                                           init_samples=None,\n",
    "#                                           logging_interval=None)\n",
    "# evaluator.plot_final_samples(images_ebm, fs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluator.plot_oods(dataset_ood='cifar10', score='gradient',train=False, fs=4, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
