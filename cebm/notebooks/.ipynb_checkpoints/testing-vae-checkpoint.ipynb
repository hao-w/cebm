{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from sebm.models import Encoder, Decoder\n",
    "from torchvision import datasets, transforms\n",
    "from sebm.data import load_data\n",
    "dataset =  'svhn' # 'svhn' # 'cifar10' # 'mnist' #  'flowers102' #\n",
    "if dataset == 'mnist' or dataset == 'fashionmnist':\n",
    "    input_channels, im_height, im_width = 1, 28, 28\n",
    "else:\n",
    "    input_channels, im_height, im_width = 3, 32, 32\n",
    "    \n",
    "device = torch.device('cuda:0')\n",
    "arch =  'simplenet2' # 'mlp'\n",
    "lr = 1e-3\n",
    "seed = 1\n",
    "latent_dim = 128\n",
    "activation = 'ReLU'\n",
    "reparameterized = True\n",
    "heldout_class = -1\n",
    "load_version = 'vae-out=%s-d=%s-seed=%s-lr=%s-zd=%s-act=%s-arch=%s' % (heldout_class, dataset, seed, lr, latent_dim, activation, arch)\n",
    "data_dir = '/home/hao/Research/sebm_data/'\n",
    "if arch == 'simplenet2':\n",
    "    if dataset == 'cifar10' or dataset == 'svhn':\n",
    "        enc = Encoder(arch=arch,\n",
    "                      reparameterized=reparameterized,\n",
    "                      im_height=im_height, \n",
    "                      im_width=im_width, \n",
    "                      input_channels=input_channels, \n",
    "                      channels=[64,128,256,512], \n",
    "                      kernels=[3,4,4,4], \n",
    "                      strides=[1,2,2,2], \n",
    "                      paddings=[1,1,1,1], \n",
    "                      hidden_dim=[128],\n",
    "                      latent_dim=latent_dim,\n",
    "                      activation=activation)\n",
    "\n",
    "        dec = Decoder(arch=arch,\n",
    "                      device=device,\n",
    "                      im_height=im_height, \n",
    "                      im_width=im_width, \n",
    "                      input_channels=input_channels, \n",
    "                      channels=[64,128,256,512], \n",
    "                      kernels=[3,4,4,4], \n",
    "                      strides=[1,2,2,2], \n",
    "                      paddings=[1,1,1,1], \n",
    "                      mlp_input_dim=latent_dim, ## TODO: hand-coded for now\n",
    "                      hidden_dim=[128],\n",
    "                      mlp_output_dim=8192,\n",
    "                      activation=activation)\n",
    "    elif dataset == 'mnist' or dataset == 'fashionmnist':\n",
    "        enc = Encoder(arch=arch,\n",
    "                      reparameterized=reparameterized,\n",
    "                      im_height=im_height, \n",
    "                      im_width=im_width, \n",
    "                      input_channels=input_channels, \n",
    "                      channels=[64,64,32,32], \n",
    "                      kernels=[3,4,4,4], \n",
    "                      strides=[1,2,2,2], \n",
    "                      paddings=[1,1,1,1], \n",
    "                      hidden_dim=[128],\n",
    "                      latent_dim=latent_dim,\n",
    "                      activation=activation)\n",
    "        dec = Decoder(arch=arch,\n",
    "                      device=device,\n",
    "                      im_height=im_height, \n",
    "                      im_width=im_width, \n",
    "                      input_channels=input_channels, \n",
    "                      channels=[64,64,32,32], \n",
    "                      kernels=[3,4,4,4], \n",
    "                      strides=[1,2,2,2], \n",
    "                      paddings=[0,0,1,1], \n",
    "                      mlp_input_dim=latent_dim, ## TODO: hand-coded for now\n",
    "                      hidden_dim=[128],\n",
    "                      mlp_output_dim=288,\n",
    "                      activation=activation)\n",
    "    else:\n",
    "        raise NotImplementError\n",
    "        \n",
    "else:\n",
    "    raise NotImplementError\n",
    "    \n",
    "enc = enc.cuda().to(device)  \n",
    "dec = dec.cuda().to(device)\n",
    "print('Loading trained models...')\n",
    "enc.load_state_dict(torch.load('../weights/cp-%s' % load_version)['enc_state_dict'])\n",
    "dec.load_state_dict(torch.load('../weights/cp-%s' % load_version)['dec_state_dict'])\n",
    "# for p in enc.parameters():\n",
    "#     p.requires_grad = False\n",
    "# for p in dec.parameters():\n",
    "#     p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sebm.eval import *\n",
    "\n",
    "# evaluator = Evaluator_VAE(enc, dec, arch, device, dataset, data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semi_nn_clf(model_name='vae', device=device, evaluator=evaluator, num_runs=10, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/hao/Research/sebm_data/SVHN/train_32x32.mat\n",
      "Using downloaded and verified file: /home/hao/Research/sebm_data/SVHN/test_32x32.mat\n",
      "2 - 1\n",
      "2 - 2\n",
      "2 - 3\n",
      "2 - 4\n",
      "2 - 5\n",
      "2 - 6\n",
      "2 - 7\n",
      "2 - 8\n",
      "2 - 9\n",
      "2 - 10\n",
      "2 - 11\n",
      "2 - 12\n",
      "2 - 13\n",
      "2 - 14\n",
      "2 - 15\n",
      "2 - 16\n",
      "2 - 17\n",
      "2 - 18\n",
      "2 - 19\n",
      "2 - 20\n",
      "2 - 21\n",
      "2 - 22\n",
      "2 - 23\n",
      "2 - 24\n",
      "2 - 25\n",
      "2 - 26\n",
      "2 - 27\n",
      "2 - 28\n",
      "2 - 29\n",
      "2 - 30\n",
      "2 - 31\n",
      "2 - 32\n",
      "2 - 33\n",
      "2 - 34\n",
      "2 - 35\n",
      "2 - 36\n",
      "2 - 37\n",
      "3 - 1\n",
      "3 - 2\n",
      "3 - 3\n",
      "3 - 4\n",
      "3 - 5\n",
      "3 - 6\n",
      "3 - 7\n",
      "3 - 8\n",
      "3 - 9\n",
      "3 - 10\n",
      "3 - 11\n",
      "3 - 12\n",
      "3 - 13\n",
      "3 - 14\n",
      "3 - 15\n",
      "3 - 16\n",
      "3 - 17\n",
      "3 - 18\n",
      "3 - 19\n",
      "3 - 20\n",
      "3 - 21\n",
      "3 - 22\n",
      "3 - 23\n",
      "3 - 24\n",
      "3 - 25\n",
      "3 - 26\n",
      "3 - 27\n",
      "3 - 28\n",
      "3 - 29\n",
      "3 - 30\n",
      "3 - 31\n",
      "3 - 32\n",
      "3 - 33\n",
      "3 - 34\n",
      "3 - 35\n",
      "3 - 36\n",
      "3 - 37\n",
      "4 - 1\n",
      "4 - 2\n",
      "4 - 3\n",
      "4 - 4\n",
      "4 - 5\n",
      "4 - 6\n",
      "4 - 7\n",
      "4 - 8\n",
      "4 - 9\n",
      "4 - 10\n",
      "4 - 11\n",
      "4 - 12\n",
      "4 - 13\n",
      "4 - 14\n",
      "4 - 15\n",
      "4 - 16\n",
      "4 - 17\n",
      "4 - 18\n",
      "4 - 19\n",
      "4 - 20\n",
      "4 - 21\n",
      "4 - 22\n",
      "4 - 23\n",
      "4 - 24\n",
      "4 - 25\n",
      "4 - 26\n",
      "4 - 27\n",
      "4 - 28\n",
      "4 - 29\n",
      "4 - 30\n",
      "4 - 31\n",
      "4 - 32\n",
      "4 - 33\n",
      "4 - 34\n",
      "4 - 35\n",
      "4 - 36\n",
      "4 - 37\n",
      "5 - 1\n",
      "5 - 2\n",
      "5 - 3\n",
      "5 - 4\n",
      "5 - 5\n",
      "5 - 6\n",
      "5 - 7\n",
      "5 - 8\n",
      "5 - 9\n",
      "5 - 10\n",
      "5 - 11\n",
      "5 - 12\n",
      "5 - 13\n",
      "5 - 14\n",
      "5 - 15\n",
      "5 - 16\n",
      "5 - 17\n",
      "5 - 18\n",
      "5 - 19\n",
      "5 - 20\n",
      "5 - 21\n",
      "5 - 22\n",
      "5 - 23\n",
      "5 - 24\n",
      "5 - 25\n",
      "5 - 26\n",
      "5 - 27\n",
      "5 - 28\n",
      "5 - 29\n",
      "5 - 30\n",
      "5 - 31\n",
      "5 - 32\n",
      "5 - 33\n",
      "5 - 34\n",
      "5 - 35\n",
      "5 - 36\n",
      "5 - 37\n",
      "6 - 1\n",
      "6 - 2\n",
      "6 - 3\n",
      "6 - 4\n",
      "6 - 5\n",
      "6 - 6\n",
      "6 - 7\n",
      "6 - 8\n",
      "6 - 9\n",
      "6 - 10\n",
      "6 - 11\n",
      "6 - 12\n",
      "6 - 13\n",
      "6 - 14\n",
      "6 - 15\n",
      "6 - 16\n",
      "6 - 17\n",
      "6 - 18\n",
      "6 - 19\n",
      "6 - 20\n",
      "6 - 21\n",
      "6 - 22\n",
      "6 - 23\n",
      "6 - 24\n",
      "6 - 25\n",
      "6 - 26\n",
      "6 - 27\n",
      "6 - 28\n",
      "6 - 29\n",
      "6 - 30\n",
      "6 - 31\n",
      "6 - 32\n",
      "6 - 33\n",
      "6 - 34\n",
      "6 - 35\n",
      "6 - 36\n",
      "6 - 37\n",
      "7 - 1\n",
      "7 - 2\n",
      "7 - 3\n",
      "7 - 4\n",
      "7 - 5\n",
      "7 - 6\n",
      "7 - 7\n",
      "7 - 8\n",
      "7 - 9\n",
      "7 - 10\n",
      "7 - 11\n",
      "7 - 12\n",
      "7 - 13\n",
      "7 - 14\n",
      "7 - 15\n",
      "7 - 16\n",
      "7 - 17\n",
      "7 - 18\n",
      "7 - 19\n",
      "7 - 20\n",
      "7 - 21\n",
      "7 - 22\n",
      "7 - 23\n",
      "7 - 24\n",
      "7 - 25\n",
      "7 - 26\n",
      "7 - 27\n",
      "7 - 28\n",
      "7 - 29\n",
      "7 - 30\n",
      "7 - 31\n",
      "7 - 32\n",
      "7 - 33\n",
      "7 - 34\n",
      "7 - 35\n",
      "7 - 36\n",
      "7 - 37\n",
      "8 - 1\n",
      "8 - 2\n",
      "8 - 3\n",
      "8 - 4\n",
      "8 - 5\n",
      "8 - 6\n",
      "8 - 7\n",
      "8 - 8\n",
      "8 - 9\n",
      "8 - 10\n",
      "8 - 11\n",
      "8 - 12\n",
      "8 - 13\n",
      "8 - 14\n",
      "8 - 15\n",
      "8 - 16\n",
      "8 - 17\n",
      "8 - 18\n",
      "8 - 19\n",
      "8 - 20\n",
      "8 - 21\n",
      "8 - 22\n",
      "8 - 23\n",
      "8 - 24\n",
      "8 - 25\n",
      "8 - 26\n",
      "8 - 27\n",
      "8 - 28\n",
      "8 - 29\n",
      "8 - 30\n",
      "8 - 31\n",
      "8 - 32\n",
      "8 - 33\n",
      "8 - 34\n",
      "8 - 35\n",
      "8 - 36\n",
      "8 - 37\n",
      "9 - 1\n",
      "9 - 2\n",
      "9 - 3\n",
      "9 - 4\n",
      "9 - 5\n",
      "9 - 6\n",
      "9 - 7\n",
      "9 - 8\n",
      "9 - 9\n",
      "9 - 10\n",
      "9 - 11\n",
      "9 - 12\n",
      "9 - 13\n",
      "9 - 14\n",
      "9 - 15\n",
      "9 - 16\n",
      "9 - 17\n",
      "9 - 18\n",
      "9 - 19\n",
      "9 - 20\n",
      "9 - 21\n",
      "9 - 22\n",
      "9 - 23\n",
      "9 - 24\n",
      "9 - 25\n",
      "9 - 26\n",
      "9 - 27\n",
      "9 - 28\n",
      "9 - 29\n",
      "9 - 30\n",
      "9 - 31\n",
      "9 - 32\n",
      "9 - 33\n",
      "9 - 34\n",
      "9 - 35\n",
      "9 - 36\n",
      "9 - 37\n",
      "10 - 1\n",
      "10 - 2\n",
      "10 - 3\n",
      "10 - 4\n",
      "10 - 5\n",
      "10 - 6\n",
      "10 - 7\n",
      "10 - 8\n",
      "10 - 9\n",
      "10 - 10\n",
      "10 - 11\n",
      "10 - 12\n",
      "10 - 13\n",
      "10 - 14\n",
      "10 - 15\n",
      "10 - 16\n",
      "10 - 17\n",
      "10 - 18\n",
      "10 - 19\n",
      "10 - 20\n",
      "10 - 21\n",
      "10 - 22\n",
      "10 - 23\n",
      "10 - 24\n",
      "10 - 25\n",
      "10 - 26\n",
      "10 - 27\n",
      "10 - 28\n",
      "10 - 29\n",
      "10 - 30\n",
      "10 - 31\n",
      "10 - 32\n",
      "10 - 33\n",
      "10 - 34\n",
      "10 - 35\n",
      "10 - 36\n",
      "10 - 37\n",
      "11 - 1\n",
      "11 - 2\n",
      "11 - 3\n",
      "11 - 4\n",
      "11 - 5\n",
      "11 - 6\n",
      "11 - 7\n",
      "11 - 8\n",
      "11 - 9\n",
      "11 - 10\n",
      "11 - 11\n",
      "11 - 12\n",
      "11 - 13\n",
      "11 - 14\n",
      "11 - 15\n",
      "11 - 16\n",
      "11 - 17\n",
      "11 - 18\n",
      "11 - 19\n",
      "11 - 20\n",
      "11 - 21\n",
      "11 - 22\n",
      "11 - 23\n",
      "11 - 24\n",
      "11 - 25\n",
      "11 - 26\n",
      "11 - 27\n",
      "11 - 28\n",
      "11 - 29\n",
      "11 - 30\n",
      "11 - 31\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/home/hao/Research/sebm_data/'\n",
    "dataset = 'svhn'\n",
    "similarity_pixel_space(dataset, dataset, data_dir, train_batch_size=2000, test_batch_size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sebm.eval import *\n",
    "# train_batch_size = 1000\n",
    "# data_dir = '/home/hao/Research/sebm_data/'\n",
    "# # dataset = 'svhn'\n",
    "# import torch\n",
    "# for i in range(3):\n",
    "#     print('processing on dataset %d' % (i+1))\n",
    "#     test_data = torch.load('/home/hao/Research/sebm_data/overviewfig/%s_test/%d.pt' % (dataset, i+1))\n",
    "#     min_distances, min_labels, nns = similarity_z_space_fewshots(evaluator, train_batch_size, test_data)\n",
    "#     plot_nearest_neighbors(test_data, nns, min_labels, min_distances, fs=1, save_name='%s_vae_%d' % (dataset, (i+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sebm.eval import *\n",
    "# train_batch_size = 1000\n",
    "# data_dir = '/home/hao/Research/sebm_data/'\n",
    "# dataset = 'mnist'\n",
    "# import torch\n",
    "# for i in range(10):\n",
    "#     print('processing on dataset %d' % (i+1))\n",
    "#     test_data = torch.load('/home/hao/Research/sebm_data/overviewfig/%s/100/%d.pt' % (dataset, i+1))\n",
    "#     min_distances, min_labels, nns = similarity_z_space_fewshots(evaluator, train_batch_size, test_data)\n",
    "#     plot_nearest_neighbors(test_data, nns, min_labels, min_distances, fs=1, save_name='%s_pixel_%d' % (dataset, (i+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fewshots(model_name='vae', evaluator=evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# NUM_SHOTs = [1, 10, 100]\n",
    "# NUM_NEIGHBORs = [1, 5, 10]\n",
    "# algo_name, seed, gamma, max_iter = 'lp', 1, 10, 30\n",
    "\n",
    "# for num_shots in NUM_SHOTs:\n",
    "#     for n_neighbors in tqdm(NUM_NEIGHBORs):\n",
    "#         accu = label_propagation(algo_name, evaluator, num_shots, seed, gamma, n_neighbors, max_iter)\n",
    "#         fout = open('label_propagation_accuracy.txt', 'a+')\n",
    "#         print('model=vae, accuracy=%s, algo=%s, seed=%d, gamma=%s, max_iter=%d, num_shots=%d, n_neighbors=%d' % (accu, algo_name, seed, gamma, max_iter, num_shots, n_neighbors), file=fout)\n",
    "#         fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics =  ['vae_10z', 'vae_50z', 'vae_128z']#, 'cebm_z', 'igebm_z']\n",
    "# datasets = ['mnist', 'cifar10']\n",
    "# import torch\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# for d in datasets:\n",
    "#     for m in metrics:\n",
    "#         plot_confusion_matrix(d, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(dataset, metric):\n",
    "    l = torch.load('confusion/logging/confusion_matrix_labels_%s_%s.pt' % (metric, dataset)).long()\n",
    "    cm = torch.zeros((10, 10))\n",
    "    for i in range(len(l)):\n",
    "        cm[l[i, 0], l[i, 1]] += 1\n",
    "    for j in range(len(cm)):\n",
    "        cm[j] /= cm[j].sum()\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    im = ax.imshow(cm, cmap='inferno', vmax=1.0, vmin=0.0)\n",
    "    ax.set_title('cm_%s_%s \\n average diagonals=%.2f' % (dataset, metric, torch.diag(cm).mean().item()), fontsize=14)\n",
    "    plt.colorbar(im)\n",
    "    ticks = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "    ax.set_xticks(np.arange(len(ticks)))\n",
    "    ax.set_yticks(np.arange(len(ticks)))\n",
    "    ax.set_xticklabels(ticks)\n",
    "    ax.set_yticklabels(ticks)\n",
    "    ax.set_ylabel('True Class Labels', fontsize=14)\n",
    "    ax.set_xlabel('Predicted Class Labels', fontsize=14)\n",
    "    for i in range(len(ticks)):\n",
    "        for j in range(len(ticks)):\n",
    "            text = ax.text(j, i, round(cm[i, j].item(), 2),\n",
    "                           ha=\"center\", va=\"center\", color=(\"k\" if i == j else 'w'))\n",
    "    plt.savefig('confusion/figures/cm_%s_%s.png' % (dataset, metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluator.oodauc(dataset_ood='svhn', score='marginal', sample_size=100, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.plot_oods(dataset='fashionmnist', train=False, score='marginal', sample_size=100, batch_size=20, density=True, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# test_batch_size = 10\n",
    "# num_random_walks = 20\n",
    "# test_batch, rand_inds = draw_one_batch(dataset, \n",
    "#                                          data_dir, \n",
    "#                                          train=False, \n",
    "#                                          normalize=False, \n",
    "#                                          flatten=False,\n",
    "#                                          rand_inds=np.array([413, 659, 869, 653, 538,  97, 447, 694, 319, 860]))\n",
    "\n",
    "# images_samples = evaluator.random_walks(num_random_walks, \n",
    "#                                         test_batch, \n",
    "#                                         sample=True)\n",
    "# nearestneighbours = evaluator.nn_latents(images_samples)\n",
    "# plot_evolving_samples(images_samples, nearestneighbours, fs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, recons = evaluator.test_one_batch(batch_size=10)\n",
    "evaluator.plot_samples(images, recons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_logistic_classifier(evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "labels = ['MNIST', 'FMNIST', 'SVHN','CIFAR10']\n",
    "cebm = [0.9755, 0.8306, 0.5758, 0.4699]\n",
    "vae = [0.9409, 0.7963, 0.3434, 0.4066]\n",
    "mlp = [0.9724, 0.8599, 0.2559, 0.1002]\n",
    "cnn = [0.9890, 0.9071, 0.9228, 0.6246]\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.2  # the width of the bars\n",
    "\n",
    "fig = plt.figure(figsize=(16, 8)) \n",
    "ax = fig.add_subplot(111)\n",
    "colors = ['#0077BB', '#EE7733', '#009988', '#AA3377', '#BBBBBB', '#EE3377', '#DDCC77']\n",
    "rects1 = ax.bar(x - 2 * width, cebm, width, color=colors[0], label='CEBM')\n",
    "rects2 = ax.bar(x - width, vae, width, color=colors[1], label='VAE')\n",
    "rects3 = ax.bar(x, mlp, width, color=colors[2], label='MLP_CLF')\n",
    "rects4 = ax.bar(x + width, cnn, width, color=colors[3], label='CNN_CLF')\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Accuracy', fontsize=18)\n",
    "ax.set_xlabel('Datasets', fontsize=18)\n",
    "ax.set_title('Logistic Regressor', fontsize=18)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels, fontsize=18)\n",
    "ax.legend(fontsize=14)\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=14)\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "autolabel(rects4)\n",
    "fig.tight_layout()\n",
    "fig.savefig('Logistic_Regressor.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "vae = torch.load(\"samples_vae.pt\")\n",
    "cebm = torch.load('samples_cebm.pt')\n",
    "pixel = torch.load('samples_pixel.pt')\n",
    "%matplotlib inline\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "num_rows, num_cols = 4, 1\n",
    "fs = 1\n",
    "fig = plt.figure(figsize=(fs * 10, fs * 7))\n",
    "gs = gridspec.GridSpec(num_rows, num_cols, figure=fig)\n",
    "gs.update(left=0.0 , bottom=0.0, right=1.0, top=1.0, wspace=0.0, hspace=0.1)\n",
    "\n",
    "gs0 = gridspec.GridSpecFromSubplotSpec(1, 10, subplot_spec=gs[0], hspace=0.0)\n",
    "gs1 = gridspec.GridSpecFromSubplotSpec(2, 10, subplot_spec=gs[1], hspace=0.0)\n",
    "gs2 = gridspec.GridSpecFromSubplotSpec(2, 10, subplot_spec=gs[2], hspace=0.0)\n",
    "gs3 = gridspec.GridSpecFromSubplotSpec(2, 10, subplot_spec=gs[3], hspace=0.0)\n",
    "\n",
    "for j in range(10):\n",
    "    ax = fig.add_subplot(gs0[0, j])\n",
    "    try:\n",
    "        ax.imshow(cebm[j,0].numpy(), cmap='gray', vmin=0, vmax=1.0)\n",
    "    except:\n",
    "        ax.imshow(np.transpose(cebm[j,0].numpy(), (1,2,0)), vmin=0, vmax=1.0)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "\n",
    "for j in range(10):\n",
    "    ax = fig.add_subplot(gs1[0, j])\n",
    "    try:\n",
    "        ax.imshow(cebm[j,1].numpy(), cmap='gray', vmin=0, vmax=1.0)\n",
    "    except:\n",
    "        ax.imshow(np.transpose(cebm[j,1].numpy(), (1,2,0)), vmin=0, vmax=1.0)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    ax = fig.add_subplot(gs1[1, j])\n",
    "    try:\n",
    "        ax.imshow(cebm[j,2].numpy(), cmap='gray', vmin=0, vmax=1.0)\n",
    "    except:\n",
    "        ax.imshow(np.transpose(cebm[j,2].numpy(), (1,2,0)), vmin=0, vmax=1.0)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "\n",
    "for j in range(10):    \n",
    "    ax = fig.add_subplot(gs2[0, j])\n",
    "    try:\n",
    "        ax.imshow(pixel[j,0].numpy(), cmap='gray', vmin=0, vmax=1.0)\n",
    "    except:\n",
    "        ax.imshow(np.transpose(pixel[j,0].numpy(), (1,2,0)), vmin=0, vmax=1.0)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    ax = fig.add_subplot(gs2[1, j])\n",
    "    try:\n",
    "        ax.imshow(pixel[j,1].numpy(), cmap='gray', vmin=0, vmax=1.0)\n",
    "    except:\n",
    "        ax.imshow(np.transpose(pixel[j,1].numpy(), (1,2,0)), vmin=0, vmax=1.0)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    \n",
    "for j in range(10): \n",
    "    ax = fig.add_subplot(gs3[0, j])\n",
    "    try:\n",
    "        ax.imshow(vae[j,0].numpy(), cmap='gray', vmin=0, vmax=1.0)\n",
    "    except:\n",
    "        ax.imshow(np.transpose(vae[j,0].numpy(), (1,2,0)), vmin=0, vmax=1.0)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    ax = fig.add_subplot(gs3[1, j])\n",
    "    try:\n",
    "        ax.imshow(vae[j,1].numpy(), cmap='gray', vmin=0, vmax=1.0)\n",
    "    except:\n",
    "        ax.imshow(np.transpose(vae[j,1].numpy(), (1,2,0)), vmin=0, vmax=1.0)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "plt.savefig('overview_figure.svg', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
