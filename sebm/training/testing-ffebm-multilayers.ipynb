{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 1.3.0 CUDA: True\n",
      "Initialize EBM, proposal and optimizer...\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from ffebm.ffebm_multilayers_testing import load_modules, test_ebm_generation, visual_samples_ebm\n",
    "CUDA = torch.cuda.is_available()\n",
    "if CUDA:\n",
    "    DEVICE = torch.device('cuda:0')\n",
    "print('torch:', torch.__version__, 'CUDA:', CUDA)\n",
    "batch_size = 100\n",
    "sample_size = 10\n",
    "latent_dims = (32, 32, 32)\n",
    "hidden_dim = 128\n",
    "mnist_size = 28\n",
    "patch_sizes = (4, 3, 3)\n",
    "reg_alpha = 0.01\n",
    "# LOAD_VERSION = 'mnist-ffebm-2layers-reg_alpha=%.2E' % (reg_alpha) \n",
    "LOAD_VERSION = 'mnist-ffebm-2layers'\n",
    "\n",
    "ebms, proposals = load_modules(patch_sizes, hidden_dim, latent_dims, LOAD_VERSION, CUDA, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def test_ebm_generation(ebms, proposals, sample_size, CUDA, DEVICE):\n",
    "    (ebm1, ebm2, ebm3) = ebms \n",
    "    (proposal1, proposal2, proposal3) = proposals\n",
    "    latent3, _ = ebm3.sample_priors(sample_size=sample_size, batch_size=1, num_patches=1)\n",
    "    images_ebm3, _ = proposal3(latent3)\n",
    "    S, B, P, _, in_channel, patch_dim2 = images_ebm3.shape\n",
    "    patch_dim = int(math.sqrt(patch_dim2))\n",
    "    images_ebm3 = images_ebm3.view(S, B, P, P, in_channel, patch_dim, patch_dim).squeeze(2).squeeze(2).permute(0, 1, 3, 4, 2)\n",
    "    images_ebm2, _ = proposal2(images_ebm3)\n",
    "    S, B, P, _, in_channel, patch_dim2 = images_ebm2.shape\n",
    "    patch_dim = int(math.sqrt(patch_dim2))\n",
    "    images_ebm2 = images_ebm2.view(S, B, P, P, in_channel, patch_dim, patch_dim).permute(0, 1, 2, 3, 5, 6, 4)\n",
    "    latent1 = torch.zeros((S, B, patch_dim*P, patch_dim*P, in_channel))\n",
    "    if CUDA:\n",
    "        latent1 = latent1.cuda().to(DEVICE)\n",
    "    for i in range(P):\n",
    "        for j in range(P):\n",
    "            latent1[:, :, i*patch_dim:(i+1)*patch_dim, j*patch_dim:(j+1)*patch_dim, :] = images_ebm2[:, :, i, j, :, :, :]\n",
    "    latent1 = latent1[:,:,1:-1, 1:-1, :]\n",
    "    images_ebm1, _ = proposal1(latent1)\n",
    "    S, B, P, _, in_channel, patch_dim2 = images_ebm1.shape\n",
    "    patch_dim = int(math.sqrt(patch_dim2))\n",
    "    images_ebm1 = images_ebm1.view(S, B, P, P, in_channel, patch_dim, patch_dim).permute(0, 1, 2, 3, 5, 6, 4)\n",
    "    images_final = torch.zeros((S, B, patch_dim*P, patch_dim*P, in_channel))\n",
    "    if CUDA:\n",
    "        images_final = images_final.cuda().to(DEVICE)\n",
    "    for i in range(P):\n",
    "        for j in range(P):\n",
    "            images_final[:, :, i*patch_dim:(i+1)*patch_dim, j*patch_dim:(j+1)*patch_dim, :] = images_ebm1[:, :, i, j, :, :, :]\n",
    "    \n",
    "    return images_final.squeeze(-1).squeeze(1).cpu().detach()\n",
    "images_final = test_ebm_generation(ebms, proposals, sample_size=10, CUDA=CUDA, DEVICE=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuEAAABZCAYAAACQRvqjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAEnElEQVR4nO3dQW7jNhQGYLKYI2TWzRkq3/8EUc+QWbd3YFcGDEMjkw35KCnfB2gTeETqibL/ISQql1ISAAAQ54/ZHQAAgO9GCAcAgGBCOAAABBPCAQAgmBAOAADBfrR8+O3trby/v7/83Lqu1ftclqWlC93a7t1uSil9fn4m9fm9M9RnJvXZd4b6uL76tK0+se2mdI76tLTfu+3a+sxk/BzXuq7/llJ+Pv89tyxReLvdysfHx8vP5Zyr99l7icTatkcszXi73ZL6/N4Z6jOT+uw7Q31cX33aVp/YdlM6R31a2u/ddm19ZjJ+jivnvJZSbs9/dzsKAAAEE8IBACCYEA4AAMGEcAAACCaEAwBAMCEcAACCCeEAABBMCAcAgGBNb8ys1bLAesvC7T2Narf3ftUndn+zHf18117bVxs/s17KMnu/Rx+PLWrfvneG368WLX28yvhpbbvmnK/reorzPcuI+oys9/2czz6nZsIBACCYEA4AAMGG3I4CAABHtHUbyoxbVMyEAwBAsCEz4Y//i+j9QBMAjLL1++U3je/gPs6/6xif8ZCmmXAAAAgmhAMAQLDp64QDwFFs/X75TeM7uPo4fzy+2euD35kJBwCAYEI4AAAEGxLCc87VWyml61ard7ullLQsS9c+juin+hy3RrX1mXkss67r2eOnt6vVZ9Z4HNH2zN+vEePxSuNn1BiqcYb6zHSG+jxeu5Ht7h23mXAAAAgmhAMAQDAhHAAAggnhAAAQTAgHAIBgQjgAAAQTwgEAIJgQDgAAwYRwAAAI9mN2B3qb/dYozm9rDD2+YcsYA0Z49Sa/O99BcA1mwgEAIJgQDk9yztUzUgAA/4cQDgAAwYRwAAAIdrkHM2EED0IBAD2ZCQcAgGBCOAAABHM7Cjy533pibXAAYBQz4QAAEKxpJnxd1+7rJ/d+Q9js9Z2PXp8RM7otxzzr/Hy13a1/31LL2vZ712fWdTPiPC/L0n2fs78vahzt+rq38Ti2zjB+RuzX+OljRLtn2OeV6j1iv2d4g+xXj9lMOAAABBPCAQAgmAczAdi0deuJh5QB+jATDgAAwcyEA7DJrDfAOGbCAQAgmBAOAADBhHAAAAgmhAMAQLCmEL4sSyqlvNxa1OxvxMNBte22bGeoT865ahvRxxH16d3Hlq13+1erz8x6zzrumX2sHT8jjmfW/lq2md/PVxo/M/s4cwyNuL5mjZ8RbZ8h/4zw1T6aCQcAgGBCOAAABLNOOABAB1u3c86+ZYLjMhMOAADBhHAAAAjmdhQAgA7cekILM+EAABBMCAcAgGBCOAAABBPCAQAgmAcz4cnWOq9bPIDDszOMidrxndI5judK1Pu1o9fI9bVv5jEfsd5mwgEAIJgQDgAAwYRwAAAIJoQDAEAwIRwAAIIJ4QAAEEwIBwCAYEI4AAAEE8IBACBYbnmDUM75n5TSr3HdOb2/Ukp/z+7EganPPvXZpz771Gef+uxTn33qs0999v1ZSvn5/MemEA4AAHyd21EAACCYEA4AAMGEcAAACCaEAwBAMCEcAACCCeEAABBMCAcAgGBCOAAABBPCAQAg2H8+tEHiNlL1FgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x7200 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visual_samples_ebm(images_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
