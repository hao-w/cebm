{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained models...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from sebm.models import Encoder, Decoder\n",
    "from torchvision import datasets, transforms\n",
    "from sebm.data import load_data\n",
    "dataset =  'mnist' # 'svhn' # 'cifar10' # 'mnist' #  'flowers102' #\n",
    "if dataset == 'mnist' or dataset == 'fashionmnist':\n",
    "    input_channels, im_height, im_width = 1, 28, 28\n",
    "else:\n",
    "    input_channels, im_height, im_width = 3, 32, 32\n",
    "    \n",
    "device = torch.device('cuda:1')\n",
    "arch =  'simplenet2' # 'mlp'\n",
    "lr = 1e-3\n",
    "seed = 1\n",
    "latent_dim = 128\n",
    "activation = 'ReLU'\n",
    "reparameterized = True\n",
    "heldout_class = -1\n",
    "load_version = 'vae-out=%s-d=%s-seed=%s-lr=%s-zd=%s-act=%s-arch=%s' % (heldout_class, dataset, seed, lr, latent_dim, activation, arch)\n",
    "data_dir = '/home/hao/Research/sebm_data/'\n",
    "if arch == 'simplenet2':\n",
    "    if dataset == 'cifar10' or dataset == 'svhn':\n",
    "        enc = Encoder(arch=arch,\n",
    "                      reparameterized=reparameterized,\n",
    "                      im_height=im_height, \n",
    "                      im_width=im_width, \n",
    "                      input_channels=input_channels, \n",
    "                      channels=[64,128,256,512], \n",
    "                      kernels=[3,4,4,4], \n",
    "                      strides=[1,2,2,2], \n",
    "                      paddings=[1,1,1,1], \n",
    "                      hidden_dim=[128],\n",
    "                      latent_dim=latent_dim,\n",
    "                      activation=activation)\n",
    "\n",
    "        dec = Decoder(arch=arch,\n",
    "                      device=device,\n",
    "                      im_height=im_height, \n",
    "                      im_width=im_width, \n",
    "                      input_channels=input_channels, \n",
    "                      channels=[64,128,256,512], \n",
    "                      kernels=[3,4,4,4], \n",
    "                      strides=[1,2,2,2], \n",
    "                      paddings=[1,1,1,1], \n",
    "                      mlp_input_dim=latent_dim, ## TODO: hand-coded for now\n",
    "                      hidden_dim=[128],\n",
    "                      mlp_output_dim=8192,\n",
    "                      activation=activation)\n",
    "    elif dataset == 'mnist' or dataset == 'fashionmnist':\n",
    "        enc = Encoder(arch=arch,\n",
    "                      reparameterized=reparameterized,\n",
    "                      im_height=im_height, \n",
    "                      im_width=im_width, \n",
    "                      input_channels=input_channels, \n",
    "                      channels=[64,64,32,32], \n",
    "                      kernels=[3,4,4,4], \n",
    "                      strides=[1,2,2,2], \n",
    "                      paddings=[1,1,1,1], \n",
    "                      hidden_dim=[128],\n",
    "                      latent_dim=latent_dim,\n",
    "                      activation=activation)\n",
    "        dec = Decoder(arch=arch,\n",
    "                      device=device,\n",
    "                      im_height=im_height, \n",
    "                      im_width=im_width, \n",
    "                      input_channels=input_channels, \n",
    "                      channels=[64,64,32,32], \n",
    "                      kernels=[3,4,4,4], \n",
    "                      strides=[1,2,2,2], \n",
    "                      paddings=[0,0,1,1], \n",
    "                      mlp_input_dim=latent_dim, ## TODO: hand-coded for now\n",
    "                      hidden_dim=[128],\n",
    "                      mlp_output_dim=288,\n",
    "                      activation=activation)\n",
    "    else:\n",
    "        raise NotImplementError\n",
    "        \n",
    "else:\n",
    "    raise NotImplementError\n",
    "    \n",
    "enc = enc.cuda().to(device)  \n",
    "dec = dec.cuda().to(device)\n",
    "print('Loading trained models...')\n",
    "enc.load_state_dict(torch.load('../weights/cp-%s' % load_version)['enc_state_dict'])\n",
    "dec.load_state_dict(torch.load('../weights/cp-%s' % load_version)['dec_state_dict'])\n",
    "# for p in enc.parameters():\n",
    "#     p.requires_grad = False\n",
    "# for p in dec.parameters():\n",
    "#     p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sebm.eval import *\n",
    "evaluator = Evaluator_VAE(enc, dec, arch, device, dataset, data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "NUM_SHOTs = [1, 10, 100]\n",
    "NUM_NEIGHBORs = [1, 5, 10]\n",
    "algo_name, seed, gamma, max_iter = 'lp', 1, 10, 30\n",
    "\n",
    "for num_shots in NUM_SHOTs:\n",
    "    for n_neighbors in tqdm(NUM_NEIGHBORs):\n",
    "        accu = label_propagation(algo_name, evaluator, num_shots, seed, gamma, n_neighbors, max_iter)\n",
    "        fout = open('label_propagation_accuracy.txt', 'a+')\n",
    "        print('model=vae, accuracy=%s, algo=%s, seed=%d, gamma=%s, max_iter=%d, num_shots=%d, n_neighbors=%d' % (accu, algo_name, seed, gamma, max_iter, num_shots, n_neighbors), file=fout)\n",
    "        fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity_ebm_z_space(evaluator, \n",
    "#                        train_batch_size=5000, \n",
    "#                        test_batch_size=5000,\n",
    "#                        model_name='vae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ys_test, pred_ys_test = evaluator.similarity_ebm_density_space(train_batch_size=200, test_batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paired = torch.cat((ys_test.unsqueeze(-1), pred_ys_test), -1)\n",
    "# torch.save(paired, 'confusion_matrix_labels_vae_z_%s.pt' % dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics =  ['vae_10z', 'vae_50z', 'vae_128z']#, 'cebm_z', 'igebm_z']\n",
    "# datasets = ['mnist', 'cifar10']\n",
    "# import torch\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# for d in datasets:\n",
    "#     for m in metrics:\n",
    "#         plot_confusion_matrix(d, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(dataset, metric):\n",
    "    l = torch.load('confusion/logging/confusion_matrix_labels_%s_%s.pt' % (metric, dataset)).long()\n",
    "    cm = torch.zeros((10, 10))\n",
    "    for i in range(len(l)):\n",
    "        cm[l[i, 0], l[i, 1]] += 1\n",
    "    for j in range(len(cm)):\n",
    "        cm[j] /= cm[j].sum()\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    im = ax.imshow(cm, cmap='inferno', vmax=1.0, vmin=0.0)\n",
    "    ax.set_title('cm_%s_%s \\n average diagonals=%.2f' % (dataset, metric, torch.diag(cm).mean().item()), fontsize=14)\n",
    "    plt.colorbar(im)\n",
    "    ticks = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "    ax.set_xticks(np.arange(len(ticks)))\n",
    "    ax.set_yticks(np.arange(len(ticks)))\n",
    "    ax.set_xticklabels(ticks)\n",
    "    ax.set_yticklabels(ticks)\n",
    "    ax.set_ylabel('True Class Labels', fontsize=14)\n",
    "    ax.set_xlabel('Predicted Class Labels', fontsize=14)\n",
    "    for i in range(len(ticks)):\n",
    "        for j in range(len(ticks)):\n",
    "            text = ax.text(j, i, round(cm[i, j].item(), 3),\n",
    "                           ha=\"center\", va=\"center\", color=(\"k\" if i == j else 'w'))\n",
    "    plt.savefig('confusion/figures/cm_%s_%s.png' % (dataset, metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_shots = 100\n",
    "# num_runs = 10\n",
    "# Accu = []\n",
    "# for i in range(num_runs):\n",
    "#     print('dataset=%s, run=%d / %d' % (dataset, i+1, num_runs))\n",
    "#     data = torch.load('/home/hao/Research/sebm_data/fewshots/%s/%d/%d.pt' % (dataset, num_shots*10, i+1))\n",
    "#     accu = train_logistic_classifier(evaluator, train_data=data)\n",
    "#     Accu.append(np.array([accu]))\n",
    "# Accu = np.concatenate(Accu)\n",
    "# print('mean=%.4f, std=%.4f' % (Accu.mean(), Accu.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluator.oodauc(dataset_ood='svhn', score='marginal', sample_size=100, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.plot_oods(dataset='fashionmnist', train=False, score='marginal', sample_size=100, batch_size=20, density=True, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# test_batch_size = 10\n",
    "# num_random_walks = 20\n",
    "# test_batch, rand_inds = draw_one_batch(dataset, \n",
    "#                                          data_dir, \n",
    "#                                          train=False, \n",
    "#                                          normalize=False, \n",
    "#                                          flatten=False,\n",
    "#                                          rand_inds=np.array([413, 659, 869, 653, 538,  97, 447, 694, 319, 860]))\n",
    "\n",
    "# images_samples = evaluator.random_walks(num_random_walks, \n",
    "#                                         test_batch, \n",
    "#                                         sample=True)\n",
    "# nearestneighbours = evaluator.nn_latents(images_samples)\n",
    "# plot_evolving_samples(images_samples, nearestneighbours, fs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, recons = evaluator.test_one_batch(batch_size=10)\n",
    "evaluator.plot_samples(images, recons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_logistic_classifier(evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "labels = ['MNIST', 'FMNIST', 'SVHN','CIFAR10']\n",
    "cebm = [0.9755, 0.8306, 0.5758, 0.4699]\n",
    "vae = [0.9409, 0.7963, 0.3434, 0.4066]\n",
    "mlp = [0.9724, 0.8599, 0.2559, 0.1002]\n",
    "cnn = [0.9890, 0.9071, 0.9228, 0.6246]\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.2  # the width of the bars\n",
    "\n",
    "fig = plt.figure(figsize=(16, 8)) \n",
    "ax = fig.add_subplot(111)\n",
    "colors = ['#0077BB', '#EE7733', '#009988', '#AA3377', '#BBBBBB', '#EE3377', '#DDCC77']\n",
    "rects1 = ax.bar(x - 2 * width, cebm, width, color=colors[0], label='CEBM')\n",
    "rects2 = ax.bar(x - width, vae, width, color=colors[1], label='VAE')\n",
    "rects3 = ax.bar(x, mlp, width, color=colors[2], label='MLP_CLF')\n",
    "rects4 = ax.bar(x + width, cnn, width, color=colors[3], label='CNN_CLF')\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Accuracy', fontsize=18)\n",
    "ax.set_xlabel('Datasets', fontsize=18)\n",
    "ax.set_title('Logistic Regressor', fontsize=18)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels, fontsize=18)\n",
    "ax.legend(fontsize=14)\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=14)\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "autolabel(rects4)\n",
    "fig.tight_layout()\n",
    "fig.savefig('Logistic_Regressor.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
